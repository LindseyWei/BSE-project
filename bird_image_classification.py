# -*- coding: utf-8 -*-
"""Bird Image Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s6trg0E0A0Quw5dTySgFuOEBoqU4jrS7
"""

import pandas as pd
import numpy as np
import os
import cv2
import glob
import matplotlib.pyplot as plt
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint
import tensorflow as tf

#Connect with google drive 
from google.colab import drive
drive.flush_and_unmount()
drive.mount('/content/gdrive', force_remount=True)

DIR_TRAIN = "../content/gdrive/MyDrive/birds/train"
DIR_VALID = "../content/gdrive/MyDrive/birds/valid"
DIR_TEST = "../content/gdrive/MyDrive/birds/test"

birds = np.array(list(os.listdir(DIR_TRAIN)))

nr_birds = 20

np.random.shuffle(birds)
birds = birds[:nr_birds]

idx_to_name = {i:x for (i,x) in enumerate(birds)}
name_to_idx = {x:i for (i,x) in enumerate(birds)}
print(idx_to_name)

def get_data_labels(path, birds, dim):
    data = []
    labels = []

    for bird in birds:
        imgs = [cv2.resize(cv2.imread(img), dim, interpolation=cv2.INTER_AREA) for img in glob.glob(path + "/" + bird + "/*.jpg")]
        for img in imgs:
            data.append(img)
            labels.append(name_to_idx[bird])
    return np.array(data), np.array(labels)

data_train, labels_train = get_data_labels(DIR_TRAIN, idx_to_name.values(), (224,224))
data_test, labels_test = get_data_labels(DIR_TEST, idx_to_name.values(), (224,224))
data_valid, labels_valid = get_data_labels(DIR_VALID, idx_to_name.values(), (224,224))

def normalize(data):
    data = data / 255.0
    data = data.astype('float32')
    return data

def one_hot(labels):
    labels = np.eye(len(np.unique(labels)))[labels]
    return labels

data_train

labels_train

data_train = normalize(data_train)
data_test = normalize(data_test)
data_valid = normalize(data_valid)

labels_train = one_hot(labels_train)
labels_test = one_hot(labels_test)
labels_valid = one_hot(labels_valid)

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.summary()

for layer in base_model.layers:
    layer.trainable = False
 
base_model.summary()

from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Model
 
# use “get_layer” method to save the last layer of the network
last_layer = base_model.get_layer('block5_pool')
# save the output of the last layer to be the input of the next layer
last_output = last_layer.output
 
# flatten the classifier input which is output of the last layer of VGG16 model
x = Flatten()(last_output)
 
# add our new softmax layer with 3 hidden units
x = Dense(nr_birds, activation='softmax', name='softmax')(x)

# instantiate a new_model using keras’s Model class
new_model = Model(inputs=base_model.input, outputs=x)
 
# print the new_model summary
new_model.summary()

new_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

checkpointer = ModelCheckpoint(filepath='birds.model.hdf5', save_best_only=True)

history = new_model.fit(data_train, labels_train, steps_per_epoch=len(data_train),
validation_data=(data_test, labels_test), validation_steps=3, epochs=5, verbose=1, callbacks=[checkpointer])

new_model.save(os.curdir)

new_model.save('content/finalmodel/')



import tensorflow as tf
# Convert the model
converter = tf.lite.TFLiteConverter.from_saved_model("content/finalmodel/") # path to the SavedModel directory
tflite_model = converter.convert()

# Save the model.
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

new_load_model = tf.keras.models.load_model("content/finalmodel/")

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path="model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test model on random input data.
input_shape = input_details[0]['shape']
##input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
dir='/content/Roadrunner_DeathValley.jpg'
input_data=cv2.imread(dir).astype("float32")
input_data=cv2.resize(input_data,(224,224))
input_data=np.expand_dims(input_data,0)#2D->3D
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

# The function `get_tensor()` returns a copy of the tensor data.
# Use `tensor()` in order to get a pointer to the tensor.
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)

input_data=cv2.imread(dir).astype("float32")
type(input_data)

input_data.shape
##input_data=np.expand_dims(input_data,0)#2D->3D
input_data=cv2.resize(input_data,(224,224))
print(input_data.shape)

x=np.argmax(output_data)
print(x)
## the index

idx_to_name[x]

output_details

input_details